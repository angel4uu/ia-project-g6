{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961869a0",
   "metadata": {},
   "source": [
    "# detect faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6fc11",
   "metadata": {},
   "source": [
    "## 0. Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af766a",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ce8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils ultralytics opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8510b",
   "metadata": {},
   "source": [
    "- Captura de rostros (capture_faces.py)\n",
    "Ejecuta un script que utiliza la webcam para capturar imágenes faciales por cada persona a reconocer.\n",
    "Las imágenes se almacenan en la carpeta lbph_data/faces/NombrePersona/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6fbe8",
   "metadata": {},
   "source": [
    "** especifica el nombre de la persona y ejecuta el script por cada persona a reconocer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cb7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../scripts/capture_faces.py --person Angela --count 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcd328",
   "metadata": {},
   "source": [
    "\n",
    "- Entrenamiento del modelo LBPH (train_lbph.py)\n",
    "Procesa las imágenes capturadas y entrena un modelo de reconocimiento facial usando el algoritmo LBPH (Local Binary Patterns Histograms).\n",
    "El modelo entrenado se guarda como modeloLBPHFace.xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../scripts/train_lbph.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64be61",
   "metadata": {},
   "source": [
    "## 1. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "646baffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6076ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde se encuentran los rostros capturados por persona\n",
    "dataPath = '../lbph_data/faces'\n",
    "imagePaths = sorted(os.listdir(dataPath))  # Asume que el orden de carpetas es el mismo que se usó en el entrenamiento\n",
    "\n",
    "# Cargar modelo entrenado de reconocimiento facial LBPH\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read('../lbph_data/lbph_model.xml')  # Ruta al modelo LBPH entrenado\n",
    "\n",
    "# Cargar modelo YOLOv8 entrenado para detección de rostros\n",
    "model = YOLO('../model.pt')  # Debe ser tu best.pt o modelo fine-tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fce3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar cámara\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Usa webcam\n",
    "# Alternativamente: cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = imutils.resize(frame, width=640)\n",
    "    auxFrame = frame.copy()\n",
    "\n",
    "    # Detección con YOLO\n",
    "    results = model(frame, verbose=False)\n",
    "    for box in results[0].boxes.xyxy:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "        rostro = auxFrame[y1:y2, x1:x2]\n",
    "        if rostro.size == 0:\n",
    "            continue\n",
    "\n",
    "        rostro_gray = cv2.cvtColor(rostro, cv2.COLOR_BGR2GRAY)\n",
    "        rostro_resized = cv2.resize(rostro_gray, (150, 150), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Reconocimiento facial\n",
    "        result = face_recognizer.predict(rostro_resized)\n",
    "\n",
    "        # Mostrar nombre\n",
    "        if result[1] < 70:\n",
    "            nombre = imagePaths[result[0]]\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            nombre = 'Desconocido'\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        cv2.putText(frame, f'{nombre} ({int(result[1])})', (x1, y1 - 10), 2, 0.8, color, 1, cv2.LINE_AA)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    cv2.imshow('Reconocimiento Facial', frame)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break  # ESC para salir\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
